{"cells":[{"cell_type":"markdown","metadata":{"id":"lH20CotmWg8i"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Colorize Black and White Photos using a Caffe Model in OpenCV**\n","\n","**In this lesson we'll learn how to use pre-trained models to automatically Colorize a Black and White (grayscale) Photo**\n"]},{"cell_type":"markdown","metadata":{"id":"wVVkWZIPXLh6"},"source":["### **Colorizing black and white images is an amazingly useful and incredible technique achieved by deep learning.** \n","\n","[Colorful Image Colorization ](http://arxiv.org/pdf/1603.08511.pdf) \n","\n","- The authors embrace the underlying uncertainty of the problem (black and white to color conversion) by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. \n","- The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. \n","- They evaluate our algorithm using a “colorization Turing test,” asking human participants to choose between a generated and ground truth color image. \n","- Their method successfully fools humans on 32% of the trials, significantly higher than previous methods.\n","\n","![](http://richzhang.github.io/colorization/resources/images/teaser3.jpg)\n","\n","by Richard Zhang, Phillip Isola, Alexei A. Efros. In ECCV, 2016.\n","\n","We'll be using the following Caffe model files that we'll download in the next cell below. These will be then loaded into OpenCV:\n","\n","1. colorization_deploy_v2.prototext\n","2. colorization_release_v2.caffe\n","3. pts_in_hull.npy"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13205,"status":"ok","timestamp":1685777488809,"user":{"displayName":"최세훈","userId":"00148754616075165078"},"user_tz":-540},"id":"ZNZLHgg9sxVP","outputId":"b4504ff3-6ade-42ae-cff0-8cd821b6dc34"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-03 07:31:15--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/colorize.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 3.5.246.157\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|3.5.246.157|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 120120413 (115M) [application/zip]\n","Saving to: ‘colorize.zip’\n","\n","colorize.zip        100%[===================>] 114.56M  20.5MB/s    in 6.4s    \n","\n","2023-06-03 07:31:22 (18.0 MB/s) - ‘colorize.zip’ saved [120120413/120120413]\n","\n"]}],"source":["!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/colorize.zip\n","!unzip -qq colorize.zip"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1685777489303,"user":{"displayName":"최세훈","userId":"00148754616075165078"},"user_tz":-540},"id":"2oKlSv7zX7Sa"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from os import listdir\n","from os.path import isfile, join\n","from matplotlib import pyplot as plt\n","\n","def imshow(title = \"Image\", image = None, size = 10):\n","  h, w = image.shape[:2]\n","  aspect_ratio = w/h\n","  plt.figure(figsize=(size * aspect_ratio,size))\n","  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  plt.axis('off')\n","  plt.title(title)\n","  plt.show()"]},{"cell_type":"code","source":["file_path = \"colorize/blackandwhite/\"\n","blackandwhite_imgs = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n","kernel = 'colorize/pts_in_hull.npy'\n","\n","net = cv2.dnn.readNetFromCaffe(\"colorize/colorization_deploy_v2.prototxt\", \"colorize/colorization_release_v2.caffemodel\")\n","print(net.getLayerNames())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lV1b8Yjxyydd","executionInfo":{"status":"ok","timestamp":1685777490000,"user_tz":-540,"elapsed":698,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"3786919c-d5cd-4352-d30e-24d48b8e21b5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["('conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'conv1_2norm', 'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'conv2_2norm', 'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3', 'relu3_3', 'conv3_3norm', 'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3', 'relu4_3', 'conv4_3norm', 'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3', 'relu5_3', 'conv5_3norm', 'conv6_1', 'relu6_1', 'conv6_2', 'relu6_2', 'conv6_3', 'relu6_3', 'conv6_3norm', 'conv7_1', 'relu7_1', 'conv7_2', 'relu7_2', 'conv7_3', 'relu7_3', 'conv7_3norm', 'conv8_1', 'relu8_1', 'conv8_2', 'relu8_2', 'conv8_3', 'relu8_3', 'conv8_313', 'conv8_313_rh', 'class8_313_rh', 'class8_ab', 'Silence')\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685777490000,"user":{"displayName":"최세훈","userId":"00148754616075165078"},"user_tz":-540},"id":"4TA6L1jhVJW3","outputId":"c13c7a15-e7ba-4ee2-8bfa-78a2d4f36654"},"outputs":[{"output_type":"stream","name":"stdout","text":["(313, 2)\n"]}],"source":["# load cluster centers\n","pts_in_hull = np.load(kernel) \n","print(pts_in_hull.shape)"]},{"cell_type":"code","source":["# populate cluster centers as 1x1 convolution kernel\n","pts_in_hull = pts_in_hull.transpose().reshape(pts_in_hull.shape[1], pts_in_hull.shape[0], 1, 1)\n","print(pts_in_hull.shape)\n","net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull.astype(np.float32)]\n","\n","# because in openCV, 'conv8_313_rh' is not filled by 2.606 even it need to be filled.\n","net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, np.float32)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dksLShZoxYa1","executionInfo":{"status":"ok","timestamp":1685777490000,"user_tz":-540,"elapsed":3,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"bf2bd837-6c17-42ae-b9a0-e88b6b254688"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 313, 1, 1)\n"]}]},{"cell_type":"code","source":["for image in blackandwhite_imgs:\n","  img = cv2.imread(file_path+image, cv2.IMREAD_GRAYSCALE)\n","  img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n","        \n","  img_rgb = (img_rgb/255.).astype(np.float32)\n","  img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n","        \n","  # pull out L channel\n","  img_l = img_lab[:,:,0]\n","        \n","  # get original image size\n","  (H_orig,W_orig) = img_rgb.shape[:2] \n","\n","  # resize image to network input size\n","  img_rs = cv2.resize(img_rgb, (224, 224)) \n","        \n","  # resize image to network input size\n","  img_lab_rs = cv2.cvtColor(img_rs, cv2.COLOR_RGB2Lab)\n","  img_l_rs = img_lab_rs[:,:,0]\n","        \n","  # subtract 50 for mean-centering\n","  img_l_rs -= 50 \n","\n","  net.setInput(cv2.dnn.blobFromImage(img_l_rs))\n","        \n","  # this is our result\n","  ab_dec = net.forward('class8_ab')[0,:,:,:].transpose((1,2,0)) \n","\n","  (H_out,W_out) = ab_dec.shape[:2]\n","  ab_dec_us = cv2.resize(ab_dec, (W_orig, H_orig))\n","  img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) \n","        \n","  # concatenate with original image L\n","  img_bgr_out = np.clip(cv2.cvtColor(img_lab_out, cv2.COLOR_Lab2BGR), 0, 1)\n","\n","  # show original image\n","  imshow('Original', img)\n","  # Resize the corlized image to it's orginal dimensions \n","  img_bgr_out = cv2.resize(img_bgr_out, (W_orig, H_orig), interpolation = cv2.INTER_AREA)\n","  imshow('Colorized', img_bgr_out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KhCatxnLkuvs88f42tPi-2U7xo5mUw4F"},"id":"_61ia56WxKDJ","executionInfo":{"status":"ok","timestamp":1685777659613,"user_tz":-540,"elapsed":14807,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"1284910f-760d-4761-d7de-42161d0c1f1f"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}