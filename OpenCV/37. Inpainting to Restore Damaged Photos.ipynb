{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CmCVqrEUlqJk"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Inpainting to Restore Damaged Photos**\n","\n","**In this lesson we'll take a damaged old photo, and restore it using the inpaint() function**\n"]},{"cell_type":"code","source":["!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n","!unzip -qq images.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjsoqdsAXBNQ","executionInfo":{"status":"ok","timestamp":1685798195474,"user_tz":-540,"elapsed":2426,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"441902ff-8d04-4245-a67e-eb54e0470c17"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-03 13:16:32--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.150.86\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.150.86|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29586716 (28M) [application/zip]\n","Saving to: ‘images.zip’\n","\n","images.zip          100%[===================>]  28.22M  17.7MB/s    in 1.6s    \n","\n","2023-06-03 13:16:34 (17.7 MB/s) - ‘images.zip’ saved [29586716/29586716]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"y6Op628PhNmX","executionInfo":{"status":"ok","timestamp":1685798196197,"user_tz":-540,"elapsed":724,"user":{"displayName":"최세훈","userId":"00148754616075165078"}}},"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","def imshow(title = \"Image\", image = None, size = 10):\n","  h, w = image.shape[:2]\n","  aspect_ratio = w/h\n","  plt.figure(figsize=(size * aspect_ratio,size))\n","  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  plt.axis('off')\n","  plt.title(title)\n","  plt.show()\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1a_IJcrulEwtQcKK_cln5dGiSjlzyvhxj"},"id":"yFnux222lRac","executionInfo":{"status":"ok","timestamp":1685798538764,"user_tz":-540,"elapsed":3603,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"ead6c0a8-1ccc-4e0f-fb3e-bedaf63090e6"},"source":["image = cv2.imread('images/abraham.jpg')\n","imshow('Original Damaged Photo', image)\n","\n","# Load the image by grayscale where we've marked the damaged areas manually\n","marked_damages = cv2.imread('images/mask.jpg', cv2.IMREAD_GRAYSCALE)\n","imshow('Marked Damages', marked_damages)\n","\n","# Let's make a mask out of our marked image be changing all colors \n","# that are not white, to black\n","ret, thresh = cv2.threshold(marked_damages, 254, 255, cv2.THRESH_BINARY)\n","imshow('Threshold Binary', thresh)\n","\n","\n","# Let's dilate (make thicker) our the marks w made\n","# since thresholding has narrowed it slightly\n","kernel = np.ones((7,7), np.uint8)\n","mask = cv2.dilate(thresh, kernel, iterations=1)\n","imshow('Dilated Mask', mask)\n","cv2.imwrite(\"images/abraham_mask.png\", mask)\n","\n","restored = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n","\n","imshow('Restored', restored)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["image = cv2.imread('images/abraham.jpg')\n","imshow('Original Damaged Photo', image)\n","\n","# Load the image by grayscale where we've marked the damaged areas manually\n","marked_damages = cv2.imread('test.png', cv2.IMREAD_GRAYSCALE)\n","imshow('Marked Damages', marked_damages)\n","\n","# Let's make a mask out of our marked image be changing all colors \n","# that are not white, to black\n","ret, thresh = cv2.threshold(marked_damages, 150, 255, cv2.THRESH_BINARY)\n","imshow('Threshold Binary', thresh)\n","\n","\n","# Let's dilate (make thicker) our the marks w made\n","# since thresholding has narrowed it slightly\n","kernel = np.ones((7,7), np.uint8)\n","mask = cv2.dilate(thresh, kernel, iterations=2)\n","imshow('Dilated Mask', mask)\n","cv2.imwrite(\"images/abraham_mask.png\", mask)\n","\n","restored = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n","\n","imshow('Restored', restored)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"140XPHCp7SQP17X0mH16goKA_vnJSxD-8"},"id":"QKwPGZd6bA0g","executionInfo":{"status":"ok","timestamp":1685798691519,"user_tz":-540,"elapsed":4875,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"b9d8579c-6b91-4069-c4e6-b01d31a7c2b3"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}