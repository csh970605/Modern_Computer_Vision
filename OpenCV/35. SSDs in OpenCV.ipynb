{"cells":[{"cell_type":"markdown","metadata":{"id":"e8UGuwMsPQlC"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Single Shot Detectors (SSDs) with OpenCV**\n","\n","####**In this lesson we'll learn how to use pre-trained models to implement an SSD in OpenCV**\n","\n","Source - https://github.com/datitran/object_detector_app/tree/master/object_detection"]},{"cell_type":"code","source":["!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n","!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/SSDs.zip\n","!unzip -qq images.zip\n","!unzip -qq SSDs.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G95V3UqtLSR9","executionInfo":{"status":"ok","timestamp":1685768598176,"user_tz":-540,"elapsed":5014,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"3d6688f0-7916-471a-dd53-697c9e5af47a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-03 05:03:13--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.143.94\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.143.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29586716 (28M) [application/zip]\n","Saving to: ‘images.zip’\n","\n","images.zip          100%[===================>]  28.22M  18.6MB/s    in 1.5s    \n","\n","2023-06-03 05:03:15 (18.6 MB/s) - ‘images.zip’ saved [29586716/29586716]\n","\n","--2023-06-03 05:03:15--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/SSDs.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.143.94\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.143.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 25547509 (24M) [application/zip]\n","Saving to: ‘SSDs.zip’\n","\n","SSDs.zip            100%[===================>]  24.36M  18.5MB/s    in 1.3s    \n","\n","2023-06-03 05:03:16 (18.5 MB/s) - ‘SSDs.zip’ saved [25547509/25547509]\n","\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"U9CKEe3bMlJO","executionInfo":{"status":"ok","timestamp":1685768599203,"user_tz":-540,"elapsed":1029,"user":{"displayName":"최세훈","userId":"00148754616075165078"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","def imshow(title = \"Image\", image = None, size = 10):\n","  h, w = image.shape[:2]\n","  aspect_ratio = w/h\n","  plt.figure(figsize=(size * aspect_ratio,size))\n","  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  plt.axis('off')\n","  plt.title(title)\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"HVsxy8E-Mnyj"},"source":["We use a TensorFlow model from TensorFlow object detection model zoo may be used to detect objects from 90 classes:\n","http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\n","\n","Text graph definition must be taken from opencv_extra:\n","https://github.com/opencv/opencv_extra/tree/master/testdata/dnn/ssd_mobilenet_v1_coco.pbtxt\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1D9Dxn7GEu_DwDNiIPPbmwr0VLq3N-TEq"},"executionInfo":{"elapsed":3448,"status":"ok","timestamp":1685768602649,"user":{"displayName":"최세훈","userId":"00148754616075165078"},"user_tz":-540},"id":"OmCCnhW2Kvzb","outputId":"8cdf5d6e-7ceb-4cbe-d723-0d01606bf8f4"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["frame = cv2.imread('./images/tommys_beers.jpeg')\n","imshow(\"original\", frame)\n","\n","print(\"Running our Single Shot Detector on our image...\")\n","image = frame.copy()\n","\n","# Set the widths and heights that are needed for input into our model\n","inWidth = 300\n","inHeight = 300\n","WHRatio = inWidth / float(inHeight)\n","\n","# These are needed for our preprocessing of our image\n","inScaleFactor = 0.007843\n","mean = np.mean(image, axis=(0,1))\n","#meanVal = 127.5\n","\n","# Point to the paths of our weights and  model architecture in a protocol buffer \n","prototxt = \"SSDs/ssd_mobilenet_v1_coco.pbtxt\"\n","weights = \"SSDs/frozen_inference_graph.pb\"\n","\n","num_classes = 90\n","threshold = 0.5\n","\n","net = cv2.dnn.readNetFromTensorflow(weights, prototxt)\n","\n","swapRB = True\n","classNames = { 0: 'background',\n","    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',\n","    7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',\n","    13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',\n","    18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',\n","    24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',\n","    32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',\n","    37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',\n","    41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',\n","    46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',\n","    51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',\n","    56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',\n","    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',\n","    67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',\n","    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',\n","    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',\n","    86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush' }\n","\n","# Create our input image blob required for input into our network    \n","blob = cv2.dnn.blobFromImage(frame, inScaleFactor, (inWidth, inHeight), (mean[2], mean[1], mean[0]), swapRB)\n","net.setInput(blob)\n","\n","# Pass our input image/blob into the network\n","detections = net.forward()\n","\n","# Crop frame if needed as we don't resize our input but take a square input\n","cols = frame.shape[1]\n","rows = frame.shape[0]\n","\n","if cols / float(rows) > WHRatio:\n","  cropSize = (int(rows * WHRatio), rows)\n","else:\n","  cropSize = (cols, int(cols / WHRatio))\n","\n","y1 = int((rows - cropSize[1]) / 2)\n","y2 = y1 + cropSize[1]\n","x1 = int((cols - cropSize[0]) / 2)\n","x2 = x1 + cropSize[0]\n","frame = frame[y1:y2, x1:x2]\n","\n","cols = frame.shape[1]\n","rows = frame.shape[0]\n","\n","# Iterate over every detection\n","for i in range(detections.shape[2]):\n","\n","  confidence = detections[0, 0, i, 2]\n","\n","  # Once confidence is greater than the threshold we get our bounding box\n","  if confidence > threshold:\n","    class_id = int(detections[0, 0, i, 1])\n","    xLeftBottom = int(detections[0, 0, i, 3] * cols)\n","    yLeftBottom = int(detections[0, 0, i, 4] * rows)\n","    xRightTop   = int(detections[0, 0, i, 5] * cols)\n","    yRightTop   = int(detections[0, 0, i, 6] * rows)\n","\n","    # Draw our bounding box over our image \n","    cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),(0, 255, 0), 3)\n","\n","    # Get our class names and put them on our image (using a white background)\n","    if class_id in classNames:\n","      label = classNames[class_id] + \": \" + str(confidence)\n","      labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","\n","      yLeftBottom = max(yLeftBottom, labelSize[1])\n","      cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]), (xLeftBottom + labelSize[0], yLeftBottom + baseLine), (255, 255, 255), cv2.FILLED)\n","      cv2.putText(frame, label, (xLeftBottom, yLeftBottom), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n","\n","imshow(\"detections\", frame)"]},{"cell_type":"markdown","metadata":{"id":"ioK2cYiLUsIO"},"source":["**Find other pretrained models here** - https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}