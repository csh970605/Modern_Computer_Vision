{"cells":[{"cell_type":"markdown","metadata":{"id":"v5tDiSqVjHux"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Neural Style Transfer with OpenCV**\n","\n","####**In this lesson we'll learn how to use pre-trained Models to implement Neural Style Transfer in OpenCV**\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NSTdemo.png)\n","\n","**About Neural Style Transfers**\n","\n","Introduced by Leon Gatys et al. in 2015, in their paper titled “[A Neural Algorithm for Artistic Style](https://arxiv.org/abs/1508.06576)”, the Neural Style Transfer algorithm went viral resulting in an explosion of further work and mobile apps.\n","\n","Neural Style Transfer enables the artistic style of an image to be applied to another image! It copies the color patterns, combinations, and brush strokes of the original source image and applies it to your input image. And is one the most impressive implementations of Neural Networks in my opinion.\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NST.png)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8M-NC6KQrJ-","executionInfo":{"status":"ok","timestamp":1685697930199,"user_tz":-540,"elapsed":12534,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"d65df5ac-3a20-4981-fb1e-b8468d402bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-02 09:25:17--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.148.158\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.148.158|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 186982232 (178M) [application/zip]\n","Saving to: ‘NeuralStyleTransfer.zip’\n","\n","NeuralStyleTransfer 100%[===================>] 178.32M  21.1MB/s    in 9.3s    \n","\n","2023-06-02 09:25:27 (19.3 MB/s) - ‘NeuralStyleTransfer.zip’ saved [186982232/186982232]\n","\n","--2023-06-02 09:25:27--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg [following]\n","--2023-06-02 09:25:28--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 392132 (383K) [image/jpeg]\n","Saving to: ‘city.jpg’\n","\n","city.jpg            100%[===================>] 382.94K  --.-KB/s    in 0.02s   \n","\n","2023-06-02 09:25:28 (17.3 MB/s) - ‘city.jpg’ saved [392132/392132]\n","\n"]}],"source":["!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg\n","!unzip -qq NeuralStyleTransfer.zip"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YMa6uOqSq1JQ","executionInfo":{"status":"ok","timestamp":1685697930200,"user_tz":-540,"elapsed":5,"user":{"displayName":"최세훈","userId":"00148754616075165078"}}},"outputs":[],"source":["import numpy as np\n","import time\n","import cv2\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from matplotlib import pyplot as plt \n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","def imshow(title = \"Image\", image = None, size = 10):\n","  h, w = image.shape[:2]\n","  aspect_ratio = w/h\n","  plt.figure(figsize=(size * aspect_ratio,size))\n","  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  plt.axis('off')\n","  plt.title(title)\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"TT7y4eiR1uwU"},"source":["### **Implement Neural Style Transfer using pretrained Models**\n","\n","We use pretrained t7 PyTorch models that can be imported using ``cv2.dnn.readNetFromTouch()```\n","\n","These models we're using come from the paper *Perceptual Losses for Real-Time Style Transfer and Super-Resolution* by Johnson et al. \n","\n","They improved proposing a Neural Style Transfer algorithm that performed 3 times faster by using a super-resolution-like problem based on perceptual loss function."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Hza0jpipvl8U","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1twcBrcfMw02U_mFW5wyCSnrp2jcOTk7t"},"outputId":"587a0848-b12b-48bc-fb36-bda785ec73e3","executionInfo":{"status":"ok","timestamp":1685698012079,"user_tz":-540,"elapsed":81882,"user":{"displayName":"최세훈","userId":"00148754616075165078"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["model_file_path = \"NeuralStyleTransfer/models/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","img = cv2.imread(\"city.jpg\")\n","mean = np.mean(img, axis=(0,1))\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","\n","  print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","  style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","  # loading our neural style transfer model \n","  neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path + model)\n","\n","  # Let's resize to a fixed height of 640 (free to change)\n","  height, width = int(img.shape[0]), int(img.shape[1])\n","  newWidth = int((640 / height) * width)\n","  resizedImg = cv2.resize(img, (newWidth, 640), interpolation=cv2.INTER_AREA)\n","\n","  # Create our blob from the image and then perform a forward pass run of the network\n","  inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (mean[2], mean[1] ,mean[0]), swapRB=False, crop=False)\n","\n","  neuralStyleModel.setInput(inpBlob)\n","  output = neuralStyleModel.forward()\n","\n","  # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","  output = output.reshape(3, output.shape[2], output.shape[3])\n","  output[0] += 103.939\n","  output[1] += 116.779\n","  output[2] += 123.68\n","  output /= 255\n","  output = output.transpose(1, 2, 0)\n","    \n","  #Display our original image, the style being applied and the final Neural Style Transfer\n","  imshow(\"Original\", img)\n","  imshow(\"Style\", style)\n","  imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"markdown","metadata":{"id":"5DeMooEJ6KMl"},"source":["## **Using the ECCV16 Updated NST Algorithm**\n","\n","In Ulyanov et al.’s 2017 publication, *Instance Normalization: The Missing Ingredient for Fast Stylization*, it was found that swapping batch normalization for instance normalization (and applying instance normalization at both training and testing), leads to even faster real-time performance and arguably more aesthetically pleasing results as well.\n","\n","Let's now use the models used by Johnson et al. in their ECCV paper.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yrJE2n8J6Jo0","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1o2LMjBm3HE52jZayBWYGGdnt74XM169n"},"executionInfo":{"status":"ok","timestamp":1685698035743,"user_tz":-540,"elapsed":23720,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"005e1fdb-9a12-4028-871d-1de762bcd320"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["model_file_path = \"NeuralStyleTransfer/models/ECCV16/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","img = cv2.imread(\"city.jpg\")\n","mean = np.mean(img, axis=(0,1))\n","\n","for (i,model) in enumerate(model_file_paths):\n","\n","  print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","  style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","\n","  neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+model)\n","\n","  height, width = int(img.shape[0]), int(img.shape[1])\n","  newWidth = int((640 / height) * width)\n","  resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","  inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (mean[2], mean[1] ,mean[0]), swapRB=False, crop=False)\n","\n","  neuralStyleModel.setInput(inpBlob)\n","  output = neuralStyleModel.forward()\n","\n","  output = output.reshape(3, output.shape[2], output.shape[3])\n","  output[0] += 103.939\n","  output[1] += 116.779\n","  output[2] += 123.68\n","  output /= 255\n","  output = output.transpose(1, 2, 0)\n","    \n","  imshow(\"Original\", img)\n","  imshow(\"Style\", style)\n","  imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"KwxO2qXuxQsp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685698035743,"user_tz":-540,"elapsed":24,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"c8d1e820-d6a8-4676-ed1a-4381dfeb7568"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-02 09:26:09--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4 [following]\n","--2023-06-02 09:26:09--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 174741 (171K) [application/octet-stream]\n","Saving to: ‘dj.mp4’\n","\n","dj.mp4              100%[===================>] 170.65K  --.-KB/s    in 0.01s   \n","\n","2023-06-02 09:26:10 (11.3 MB/s) - ‘dj.mp4’ saved [174741/174741]\n","\n"]}],"source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"N4T20P3hyi2R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685698035744,"user_tz":-540,"elapsed":22,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"b13c8445-8448-44d5-adeb-bf9daffc7196"},"outputs":[{"output_type":"stream","name":"stdout","text":["Completed 1 Frame(s)\n","Completed 2 Frame(s)\n","Completed 3 Frame(s)\n","Completed 4 Frame(s)\n","Completed 5 Frame(s)\n","Completed 6 Frame(s)\n","Completed 7 Frame(s)\n","Completed 8 Frame(s)\n","Completed 9 Frame(s)\n","Completed 10 Frame(s)\n","Completed 11 Frame(s)\n","Completed 12 Frame(s)\n","Completed 13 Frame(s)\n","Completed 14 Frame(s)\n","Completed 15 Frame(s)\n","Completed 16 Frame(s)\n","Completed 17 Frame(s)\n","Completed 18 Frame(s)\n","Completed 19 Frame(s)\n","Completed 20 Frame(s)\n","Completed 21 Frame(s)\n","Completed 22 Frame(s)\n","Completed 23 Frame(s)\n","Completed 24 Frame(s)\n","Completed 25 Frame(s)\n","Completed 26 Frame(s)\n","Completed 27 Frame(s)\n","Completed 28 Frame(s)\n","Completed 29 Frame(s)\n","Completed 30 Frame(s)\n","Completed 31 Frame(s)\n","Completed 32 Frame(s)\n","Completed 33 Frame(s)\n"]}],"source":["model_file_path = \"NeuralStyleTransfer/models/ECCV16/starry_night.t7\"\n","\n","cap = cv2.VideoCapture('dj.mp4')\n","\n","w = int(cap.get(3)) \n","h = int(cap.get(4))\n","\n","out = cv2.VideoWriter('NST_Starry_Night.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (w, h))\n","\n","style = cv2.imread(\"NeuralStyleTransfer/art/starry_night.jpg\")\n","i = 0\n","mean = np.mean(img, axis=(0,1))\n","\n","while True:\n","\n","  ret, img = cap.read()\n","  \n","  if ret == True:\n","\n","    i += 1\n","    print(\"Completed {} Frame(s)\".format(i))\n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path)\n","\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (mean[2], mean[1] ,mean[0]), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","      \n","    vid_output = (output * 255).astype(np.uint8)\n","    vid_output = cv2.resize(vid_output, (w, h), interpolation = cv2.INTER_AREA)\n","    out.write(vid_output)\n","  else:\n","    break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"markdown","metadata":{"id":"lT2qx3vjkmw_"},"source":["## **Display your video**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Xoh5tjVlkivx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685698035744,"user_tz":-540,"elapsed":17,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"d7826fa2-1546-4274-f200-f8732c81afc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 31.100 / 56. 31.100\n","  libavcodec     58. 54.100 / 58. 54.100\n","  libavformat    58. 29.100 / 58. 29.100\n","  libavdevice    58.  8.100 / 58.  8.100\n","  libavfilter     7. 57.100 /  7. 57.100\n","  libavresample   4.  0.  0 /  4.  0.  0\n","  libswscale      5.  5.100 /  5.  5.100\n","  libswresample   3.  5.100 /  3.  5.100\n","  libpostproc    55.  5.100 / 55.  5.100\n","Input #0, avi, from '/content/NST_Starry_Night.avi':\n","  Metadata:\n","    encoder         : Lavf59.27.100\n","  Duration: 00:00:01.10, start: 0.000000, bitrate: 27624 kb/s\n","    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 640x360, 28439 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mprofile High, level 3.0\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=11 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'NST_Starry_Night.mp4':\n","  Metadata:\n","    encoder         : Lavf58.29.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x360, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n","    Metadata:\n","      encoder         : Lavc58.54.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame=   33 fps=0.0 q=-1.0 Lsize=    1699kB time=00:00:01.00 bitrate=13920.3kbits/s speed=1.61x    \n","video:1698kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.059398%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mframe I:1     Avg QP:32.59  size: 54233\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mframe P:29    Avg QP:32.42  size: 52719\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mframe B:3     Avg QP:32.70  size: 51784\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mconsecutive B-frames: 84.8%  6.1%  9.1%  0.0%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mmb I  I16..4:  0.0% 97.7%  2.3%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mmb P  I16..4:  0.2% 77.2% 16.5%  P16..4:  1.6%  2.8%  1.8%  0.0%  0.0%    skip: 0.0%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mmb B  I16..4:  0.0% 68.9% 19.0%  B16..8:  3.6%  5.2%  2.4%  direct: 0.9%  skip: 0.0%  L0:56.6% L1:15.9% BI:27.6%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0m8x8 transform intra:82.4% inter:60.3%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mcoded y,uvDC,uvAC intra: 99.2% 99.6% 97.1% inter: 98.8% 94.6% 64.2%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mi16 v,h,dc,p: 28% 47% 10% 16%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 17% 18%  6%  8%  9%  9%  6% 16%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 14% 12%  8% 11% 11% 11%  7% 14%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mi8c dc,h,v,p: 58% 19% 11% 12%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mWeighted P-Frames: Y:20.7% UV:13.8%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mref P L0: 31.7% 11.4% 31.5% 21.9%  3.4%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mref B L0: 80.0% 20.0%\n","\u001b[1;36m[libx264 @ 0x5563d5f0c580] \u001b[0mkb/s:12643.08\n"]}],"source":["!ffmpeg -i /content/NST_Starry_Night.avi NST_Starry_Night.mp4 -y"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"S5k0A0IBkjgs","colab":{"base_uri":"https://localhost:8080/","height":320,"output_embedded_package_id":"114Oaci3Es-WrxiBln2O9rqchFpnWBBGT"},"executionInfo":{"status":"ok","timestamp":1685698035744,"user_tz":-540,"elapsed":14,"user":{"displayName":"최세훈","userId":"00148754616075165078"}},"outputId":"264ae04c-c4da-4ab8-9abf-67441317f8bb"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["video_path = '/content/NST_Starry_Night.mp4'\n"," \n","mp4 = open(video_path, \"rb\").read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=600 controls><source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"btppBi7XIKhp"},"source":["## **Want to train your own NST Model?**\n","\n","## **Look at later sections of the course where we take a look at Implementing our very own Deep Learning NST Algorithm**\n","\n","Alternatively, give this github repo a shot and try it yourself - https://github.com/jcjohnson/fast-neural-style"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}